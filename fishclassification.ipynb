{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/berraoguz/fishclassification?scriptVersionId=203136113\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Fish Classification Using Artificial Neural Networks\n\nBu projede, bir balık sınıflandırma veri setini kullanarak bir yapay sinir ağı (ANN) modeli eğiteceğiz. Aşama aşama veri önişlemeden modelin eğitilmesine kadar süreci takip edeceğiz.\n","metadata":{}},{"cell_type":"code","source":"# Gerekli kütüphanelerin yüklenmesi\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom sklearn.utils import class_weight\n\n# GPU kontrolü\nprint(\"Kullanılabilir GPU'lar:\", tf.config.list_physical_devices('GPU'))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Veri Önişleme\n\nBu bölümde veri setimizi yükleyecek ve etiketler ile dosya yollarını içeren bir DataFrame oluşturacağız.\n","metadata":{}},{"cell_type":"code","source":"# Label ve path listeleri\nlabels = []\npaths = []\n\n# Veri seti dizini\nfish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\n# os.walk ile klasörleri dolaşma\nfor dir_name, _, filenames in os.walk(fish_dir):\n    for filename in filenames:\n        if os.path.splitext(filename)[-1] == '.png':  # PNG uzantılı dosyaları al\n            if 'GT' not in dir_name.split():  # 'GT' klasörlerini atla\n                labels.append(os.path.split(dir_name)[-1])\n                paths.append(os.path.join(dir_name, filename))\n\n# DataFrame oluşturma\ndata = pd.DataFrame({\n    'path': paths,\n    'label': labels\n})\n\n# İlk birkaç satırı inceleme\nprint(\"Veri setinin ilk 5 satırı:\")\nprint(data.head())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Veriyi Görselleştirme\n\nRastgele bir resim seçip etiketini göstereceğiz.\n","metadata":{}},{"cell_type":"code","source":"# Rastgele bir resim seç ve göster\nrandom_image = data.sample(1).iloc[0]\nimg_path = random_image['path']\nimg = mpimg.imread(img_path)\n\nplt.imshow(img)\nplt.title(f\"Label: {random_image['label']}\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Veriyi Train ve Test Olarak Ayırma\n\nVeri setimizi eğitim ve test verisi olarak ayıracağız.\n","metadata":{}},{"cell_type":"code","source":"train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label'], random_state=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Modelin Eğitilmesi (ANN)\n\nBurada yapay sinir ağı modelimizi oluşturup eğiteceğiz.\n","metadata":{}},{"cell_type":"code","source":"# ImageDataGenerator ile veri ön işleme\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_data, \n    x_col='path', \n    y_col='label', \n    target_size=(224, 224),\n    batch_size=32, \n    class_mode='categorical'\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_data, \n    x_col='path', \n    y_col='label', \n    target_size=(224, 224),\n    batch_size=32, \n    class_mode='categorical'\n)\n\n# Class_weight hesaplama\nclass_weights = class_weight.compute_class_weight(\n    'balanced',\n    classes=np.unique(train_data['label']),\n    y=train_data['label']\n)\nclass_weights_dict = dict(enumerate(class_weights))\n\n# ANN modeli\nmodel = Sequential([\n    Flatten(input_shape=(224, 224, 3)),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dense(len(train_generator.class_indices), activation='softmax')  \n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Modeli eğitme\ntry:\n    with tf.device('/GPU:0'):  \n        steps_per_epoch = 180  \n        history = model.fit(\n            train_generator, \n            steps_per_epoch=steps_per_epoch,\n            epochs=10,  \n            validation_data=test_generator,\n            class_weight=class_weights_dict  \n        )\nexcept RuntimeError as e:\n    print(f\"GPU kullanılamadı: {e}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Modelin Değerlendirilmesi\n\nModelimizin test setindeki başarısını değerlendireceğiz.\n","metadata":{}},{"cell_type":"code","source":"# Modelin doğrulama setindeki başarısını değerlendirme\ny_pred = np.argmax(model.predict(test_generator), axis=1)\ny_true = test_generator.classes\n\n# Confusion matrix oluşturma\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys(), zero_division=1))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Eğitim ve Doğrulama Kaybını Görselleştirme\n\nModelin eğitim ve doğrulama kaybını zamanla göreceğiz.\n","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss Over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}